{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution: \n",
    "\n",
    "   * Most material is adapted from [Agustinus Kristiadi's blog](https://wiseodd.github.io/techblog/2017/01/24/vae-pytorch/) and [Generative models repository](https://github.com/wiseodd/generative-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder\n",
    "\n",
    "We're now doing to use PyTorch to implement a *vanilla* version of one of the most popular generative models today, the VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import os\n",
    "\n",
    "import torchvision\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalizes in the range [0.0, 1.0]\n",
    "    download=True,                                  # download it if you don't have it\n",
    ")\n",
    "\n",
    "mb_size = 64\n",
    "Z_dim = 100\n",
    "n_r = mnist_train.train_data.shape[1]\n",
    "n_c = mnist_train.train_data.shape[2]\n",
    "X_dim =  n_r * n_c\n",
    "h_dim = 128\n",
    "lr = 1e-3\n",
    "c = 0\n",
    "n_samples = mb_size # used for visualization during learning\n",
    "\n",
    "assert(n_samples <= mb_size)  # this is assumed below\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=mnist_train, batch_size=mb_size,\n",
    "                               shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meet the Encoder and Decoder\n",
    "\n",
    "\n",
    "Like the GAN, a VAE has two parts. The Decoder $P(X|z)$ is analagous to the Generator in the GAN.\n",
    "\n",
    "The Encoder $Q(z|X)$ is used for approximate inference.\n",
    "\n",
    "Let's start by constructing the Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again use Xavier initialization\n",
    "Wxh = torch.empty(X_dim, h_dim)\n",
    "nn.init.xavier_normal_(Wxh)\n",
    "Wxh = Variable(Wxh, requires_grad=True)\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whz_mu = torch.empty(h_dim, Z_dim)\n",
    "nn.init.xavier_normal_(Whz_mu)\n",
    "Whz_mu = Variable(Whz_mu, requires_grad=True)\n",
    "bhz_mu = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "\n",
    "Whz_var = torch.empty(h_dim, Z_dim)\n",
    "nn.init.xavier_normal_(Whz_var)\n",
    "Whz_var = Variable(Whz_var, requires_grad=True)\n",
    "bhz_var = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def Q(X):\n",
    "    h = F.relu(X.mm(Wxh) + bxh)\n",
    "    z_mu = h.mm(Whz_mu) + bhz_mu\n",
    "    z_var = h.mm(Whz_var) + bhz_var\n",
    "    return z_mu, z_var\n",
    "\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    eps = Variable(torch.randn(mb_size, Z_dim))\n",
    "    return mu + torch.exp(log_var / 2) * eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `sample_z' is implementing the reparameterization trick.\n",
    "\n",
    "Now, we define the Decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wzh = torch.empty(Z_dim, h_dim)\n",
    "nn.init.xavier_normal_(Wzh)\n",
    "Wzh = Variable(Wzh, requires_grad=True)\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = torch.empty(h_dim, X_dim)\n",
    "nn.init.xavier_normal_(Whx)\n",
    "Whx = Variable(Whx, requires_grad=True)\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "def P(z):\n",
    "    h = F.relu(z.mm(Wzh) + bzh)\n",
    "    X = torch.sigmoid(h.mm(Whx) + bhx)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [Wxh, bxh, Whz_mu, bhz_mu, Whz_var, bhz_var,\n",
    "          Wzh, bzh, Whx, bhx]\n",
    "\n",
    "solver = optim.Adam(params, lr=lr)\n",
    "\n",
    "def reset_grad():\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step\n",
    "\n",
    "We'll wrap everything up in a training loop soon, but for now, let's walk through a single iteration.\n",
    "\n",
    "First, we'll grab a batch of data for demonstration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data as input to the discriminator\n",
    "X, _ = next(iter(train_loader))\n",
    "X = Variable(X.view(-1, X_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, push that data through our Encoder to get the means and variances of $z$ for the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mu, z_var = Q(X)\n",
    "print(z_mu.size())\n",
    "print(z_var.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then sample a batch of $z$s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sample_z(z_mu, z_var)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take the batch of sampled $z$s and push them through the Decoder to get $X$ (note that it isn't sampled, we are just returning the mean computed by the Decoder):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = P(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't even bother to show these, because the learning hasn't started yet so we would just see noise.\n",
    "\n",
    "With the encoding and decoding done, we can compute the two loss terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_loss = F.binary_cross_entropy(X_sample, X, reduction='sum') / mb_size\n",
    "kl_loss = torch.mean(0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1. - z_var, 1))\n",
    "loss = recon_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've computed the loss, we can backprop through the decoder and the encoder, thanks to the reparameterization trick, and then apply the parameter update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "solver.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual in PyTorch, we need to clear gradients so that they don't accumulate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together in a learning loop\n",
    "\n",
    "Alright, let's put these steps together and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(100000):\n",
    "    X, _ = next(iter(train_loader))\n",
    "    X = Variable(X.view(-1, X_dim))\n",
    "\n",
    "    # Forward\n",
    "    z_mu, z_var = Q(X)\n",
    "    z = sample_z(z_mu, z_var)\n",
    "    X_sample = P(z)\n",
    "\n",
    "    # Loss\n",
    "    recon_loss = F.binary_cross_entropy(X_sample, X, reduction='sum') / mb_size\n",
    "    kl_loss = torch.mean(0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1. - z_var, 1))\n",
    "    loss = recon_loss + kl_loss\n",
    "\n",
    "    # Backward\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; Loss: {:.4}'.format(it, loss.item()))\n",
    "\n",
    "        samples = P(z).data.numpy()[:n_samples]\n",
    "\n",
    "        n_gs = int(np.sqrt(n_samples))\n",
    "        \n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(n_gs, n_gs)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('out_vae/'):\n",
    "            os.makedirs('out_vae/')\n",
    "\n",
    "        plt.savefig('out_vae/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
    "        c += 1\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
